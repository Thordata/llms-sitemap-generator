"""
LLMS Sitemap Generator - GUI Tool
åŸºäº PyQt5 çš„å¯è§†åŒ–é…ç½®å·¥å…·
"""

from __future__ import annotations

import sys
from pathlib import Path
from typing import List, Optional

try:
    from PyQt5.QtWidgets import (
        QApplication,
        QMainWindow,
        QWidget,
        QVBoxLayout,
        QHBoxLayout,
        QPushButton,
        QLabel,
        QTextEdit,
        QTreeWidget,
        QTreeWidgetItem,
        QSplitter,
        QTabWidget,
        QLineEdit,
        QCheckBox,
        QSpinBox,
        QGroupBox,
        QMessageBox,
        QProgressBar,
        QFileDialog,
        QComboBox,
        QScrollArea,
        QSizePolicy,
    )
    from PyQt5.QtCore import Qt, QThread, pyqtSignal
    from PyQt5.QtGui import QFont
except ImportError:
    print("PyQt5 is not installed. Please install it with: pip install PyQt5")
    sys.exit(1)

from .config import (
    load_config,
    AppConfig,
    SiteConfig,
    FiltersConfig,
    OutputConfig,
    SourceConfig,
    FilterRule,
)
from .sitemap import collect_urls_from_sources
from .filters import filter_and_group_urls, PageEntry
from .generator import generate_llms_txt, generate_llms_from_urls
from .logger import get_logger
from urllib.parse import urlparse

logger = get_logger(__name__)

try:
    import yaml
except ImportError:
    yaml = None  # å¦‚æœ yaml æœªå®‰è£…ï¼Œä¼šåœ¨ä¿å­˜é…ç½®æ—¶æç¤º


class URLCollectionThread(QThread):
    """åå°çº¿ç¨‹ï¼šæ”¶é›† URL"""

    progress = pyqtSignal(str)
    finished = pyqtSignal(list, list)  # (urls, failed_urls)
    error = pyqtSignal(str)

    def __init__(self, config: AppConfig):
        super().__init__()
        self.config = config

    def run(self):
        try:
            import requests

            session = requests.Session()
            self.progress.emit("æ­£åœ¨æ”¶é›† URL...")

            # æ”¶é›†å¤±è´¥çš„URLåˆ—è¡¨
            failed_urls = []
            urls = collect_urls_from_sources(
                self.config, session, failed_urls=failed_urls
            )
            self.finished.emit(urls, failed_urls)
        except Exception as e:
            self.error.emit(str(e))


class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.config: Optional[AppConfig] = None
        self.all_urls: List[str] = []
        self.filtered_pages: List[PageEntry] = []
        self.failed_urls: List[dict] = []  # å­˜å‚¨å¤±è´¥çš„URL
        self.discovered_subdomains: set = set()  # å­˜å‚¨å‘ç°çš„å­åŸŸå
        self.group_items: dict = {}  # å­˜å‚¨åˆ†ç»„é¡¹
        self.collection_thread: Optional[URLCollectionThread] = None
        self.init_ui()

    def init_ui(self):
        self.setWindowTitle("LLMS Sitemap Generator - GUI Tool")
        # è®©åˆå§‹çª—å£å°ºå¯¸å°½é‡è½åœ¨å±å¹•å¯ç”¨åŒºåŸŸå†…ï¼ˆé¿å¼€ä»»åŠ¡æ ï¼‰ï¼Œé¿å…åº•éƒ¨æŒ‰é’®è¢«é®æŒ¡
        try:
            screen = QApplication.primaryScreen()
            if screen:
                geo = screen.availableGeometry()
                w = min(1200, max(900, geo.width() - 80))
                h = min(800, max(650, geo.height() - 80))
                self.setGeometry(100, 60, w, h)
            else:
                self.setGeometry(100, 60, 1200, 800)
        except Exception:
            self.setGeometry(100, 60, 1200, 800)

        # ä¸»çª—å£éƒ¨ä»¶
        central_widget = QWidget()
        self.setCentralWidget(central_widget)

        # ä¸»å¸ƒå±€ï¼šä½¿ç”¨ QSplitter æ”¯æŒæ‹–æ‹½è°ƒæ•´å·¦å³å®½åº¦
        main_layout = QHBoxLayout(central_widget)
        splitter = QSplitter(Qt.Horizontal)

        # å·¦ä¾§ï¼šé…ç½®é¢æ¿ï¼ˆå†…éƒ¨å¯æ»šåŠ¨ + åº•éƒ¨æŒ‰é’®å›ºå®šï¼‰
        config_panel = self.create_config_panel()
        splitter.addWidget(config_panel)

        # å³ä¾§ï¼šURL é¢„è§ˆåŒºåŸŸ
        preview_panel = self.create_preview_panel()
        splitter.addWidget(preview_panel)

        splitter.setStretchFactor(0, 1)
        splitter.setStretchFactor(1, 2)
        main_layout.addWidget(splitter)

    def create_config_panel(self) -> QWidget:
        """åˆ›å»ºé…ç½®é¢æ¿"""
        panel = QWidget()
        layout = QVBoxLayout(panel)
        layout.setContentsMargins(8, 8, 8, 8)
        layout.setSpacing(8)

        # è®©å†…å®¹åŒºåŸŸå¯æ»šåŠ¨ï¼šé¿å…çª—å£é«˜åº¦è¾ƒå°æ—¶åº•éƒ¨æŒ‰é’®è¢«é®æŒ¡
        content = QWidget()
        content_layout = QVBoxLayout(content)
        content_layout.setContentsMargins(0, 0, 0, 0)
        content_layout.setSpacing(10)

        # ç«™ç‚¹é…ç½®
        site_group = QGroupBox("Site Settings / ç«™ç‚¹é…ç½®")
        site_layout = QVBoxLayout()

        # Base URLï¼šä»¥è‹±æ–‡ä¸ºä¸»ï¼Œé™„å¸¦ä¸­æ–‡è¯´æ˜
        self.base_url_input = QLineEdit("https://example.com")
        base_url_label = QLabel("Base URLï¼ˆç«™ç‚¹ä¸»åŸŸåï¼‰:")
        base_url_label.setToolTip(
            "Website base URL, e.g. https://example.com or https://www.example.com"
        )
        site_layout.addWidget(base_url_label)
        site_layout.addWidget(self.base_url_input)

        self.default_lang_input = QLineEdit("en")
        default_lang_label = QLabel("Default Languageï¼ˆé»˜è®¤è¯­è¨€ä»£ç ï¼Œå¦‚ en/zhï¼‰:")
        default_lang_label.setToolTip(
            "Two-letter language code (IETF), used to keep only this language in llms.txt"
        )
        site_layout.addWidget(default_lang_label)
        site_layout.addWidget(self.default_lang_input)

        # æ˜¯å¦è‡ªåŠ¨ä» sitemap ä¸­å‘ç°å­åŸŸï¼ˆç±»ä¼¼ crt.sh æ€è·¯ï¼Œä½†åŸºäºç«™ç‚¹è‡ªèº« sitemapï¼‰
        self.auto_subdomains_check = QCheckBox(
            "Auto-discover subdomains from sitemapï¼ˆè‡ªåŠ¨ä» sitemap å‘ç°å­åŸŸï¼Œæ¨èå¼€å¯ï¼‰"
        )
        self.auto_subdomains_check.setChecked(True)
        self.auto_subdomains_check.setToolTip(
            "Try to discover additional subdomains (e.g. blog.example.com, docs.example.com) "
            "by parsing sitemap.xml and automatically add them to allowed domains & sources."
        )
        site_layout.addWidget(self.auto_subdomains_check)

        # å­åŸŸåå‘ç°å’Œé€‰æ‹©åŒºåŸŸ
        subdomain_group = QGroupBox("Subdomain Discovery / å­åŸŸåå‘ç°")
        subdomain_layout = QVBoxLayout()

        # å‘ç°æŒ‰é’®
        discover_btn_layout = QHBoxLayout()
        self.discover_subdomains_btn = QPushButton(
            "ğŸ” Discover Subdomains / å‘ç°å­åŸŸå"
        )
        self.discover_subdomains_btn.setToolTip(
            "Click to discover all subdomains from sitemap and homepage. "
            "After discovery, you can select which subdomains to include."
        )
        self.discover_subdomains_btn.clicked.connect(self.on_discover_subdomains)
        discover_btn_layout.addWidget(self.discover_subdomains_btn)

        self.select_all_subdomains_btn = QPushButton("Select All")
        self.select_all_subdomains_btn.clicked.connect(self.select_all_subdomains)
        self.select_all_subdomains_btn.setEnabled(False)
        discover_btn_layout.addWidget(self.select_all_subdomains_btn)

        self.deselect_all_subdomains_btn = QPushButton("Deselect All")
        self.deselect_all_subdomains_btn.clicked.connect(self.deselect_all_subdomains)
        self.deselect_all_subdomains_btn.setEnabled(False)
        discover_btn_layout.addWidget(self.deselect_all_subdomains_btn)

        discover_btn_layout.addStretch()
        subdomain_layout.addLayout(discover_btn_layout)

        # å­åŸŸååˆ—è¡¨
        self.subdomain_list = QTreeWidget()
        self.subdomain_list.setHeaderLabels(
            ["Subdomain / å­åŸŸå", "Status / çŠ¶æ€", "Source / æ¥æº"]
        )
        self.subdomain_list.setMaximumHeight(120)
        self.subdomain_list.setToolTip(
            "List of discovered subdomains. Check/uncheck to include/exclude from crawling."
        )
        subdomain_layout.addWidget(self.subdomain_list)

        subdomain_group.setLayout(subdomain_layout)
        site_layout.addWidget(subdomain_group)

        # å­˜å‚¨å‘ç°çš„å­åŸŸå
        self.discovered_subdomains = set()

        # ç«™ç‚¹æè¿°ï¼šç”¨äº llms.txt é¡¶éƒ¨çš„ Site Overviewï¼Œå¸®åŠ©çš„è¯´æ˜æ€§æ–‡æ¡ˆ
        self.site_desc_edit = QTextEdit()
        self.site_desc_edit.setPlaceholderText(
            "Optional: short site overview in EN (recommended), will appear at the top of llms.txt as "
            "'Site Overview'.\n"
            "ä¾‹å¦‚ï¼ˆä¸­æ–‡æç¤ºï¼‰ï¼šç®€è¦è¯´æ˜ä½ çš„ç½‘ç«™æä¾›ä»€ä¹ˆäº§å“/æœåŠ¡ã€é¢å‘å“ªäº›ç”¨æˆ·ã€æœ‰å“ªäº›ä¸»è¦æ¿å—ã€‚"
        )
        self.site_desc_edit.setFixedHeight(70)
        site_layout.addWidget(QLabel("Site Descriptionï¼ˆç«™ç‚¹æ¦‚è§ˆï¼Œå¯é€‰ï¼Œå»ºè®®è‹±æ–‡ï¼‰:"))
        site_layout.addWidget(self.site_desc_edit)

        site_group.setLayout(site_layout)
        content_layout.addWidget(site_group)

        # æ•°æ®æºé…ç½®
        source_group = QGroupBox("Sources / æ•°æ®æº")
        source_layout = QVBoxLayout()

        self.sitemap_url_input = QLineEdit("https://example.com/sitemap.xml")
        sitemap_label = QLabel("Sitemap URLï¼ˆå¦‚æœç«™ç‚¹æœ‰ sitemap.xmlï¼Œå¼ºçƒˆæ¨èå¡«å†™ï¼‰:")
        sitemap_label.setToolTip(
            "Primary sitemap.xml or sitemap index URL for the site you are configuring."
        )
        source_layout.addWidget(sitemap_label)
        source_layout.addWidget(self.sitemap_url_input)

        # é¢å¤–çˆ¬å–å…¥å£ï¼ˆä¾‹å¦‚ /blogï¼‰ï¼Œç”¨äºè¡¥å…… sitemap ä¸­æ²¡æœ‰è¦†ç›–åˆ°çš„å†…å®¹
        self.crawl_url_input = QLineEdit("")
        self.crawl_url_input.setPlaceholderText(
            "e.g. https://example.com/blog æˆ– https://example.com/docsï¼ˆå¯é€‰ï¼‰"
        )
        crawl_label = QLabel("Crawl Start URLï¼ˆå¯é€‰ï¼Œå»ºè®®å¡«å†™ Blog æˆ– Docs å…¥å£ï¼‰:")
        crawl_label.setToolTip(
            "Optional crawl start URL to complement sitemap, e.g. /blog or /docs. "
            "For JS-heavy blogs that are hard to discover via sitemap, this is important."
        )
        source_layout.addWidget(crawl_label)
        source_layout.addWidget(self.crawl_url_input)

        crawl_row = QHBoxLayout()
        self.crawl_depth_spin = QSpinBox()
        self.crawl_depth_spin.setRange(1, 10)
        # é»˜è®¤æ·±åº¦ä» 3 è°ƒä½åˆ° 2ï¼Œé€‚åˆå¤§å¤šæ•° B2B ç«™ç‚¹çš„ã€Œä¸»å¯¼èˆª + ä¸€çº§å†…å®¹ã€é‡‡æ ·ï¼Œ
        # å¯ä»¥æ˜æ˜¾å‡å°‘è¯·æ±‚æ•°é‡ï¼ŒåŠ å¿«åˆæ¬¡è·‘ç«™æ—¶é—´
        self.crawl_depth_spin.setValue(2)
        crawl_row.addWidget(QLabel("Max Depthï¼ˆçˆ¬å–æ·±åº¦ï¼‰:"))
        crawl_row.addWidget(self.crawl_depth_spin)

        self.crawl_max_urls_spin = QSpinBox()
        self.crawl_max_urls_spin.setRange(10, 20000)
        # é»˜è®¤å•å…¥å£æœ€å¤š URL æ•°ä» 500 è°ƒæ•´åˆ° 200ï¼Œ
        # åœ¨ã€Œsitemap + crawlã€ç»„åˆåœºæ™¯ä¸‹æ›´é€‚åˆä½œä¸ºè¡¥å……é‡‡æ ·ï¼Œé¿å… crawl æˆä¸ºä¸»è¦è€—æ—¶ç“¶é¢ˆ
        self.crawl_max_urls_spin.setValue(200)
        crawl_row.addWidget(QLabel("Max URLsï¼ˆå•å…¥å£æœ€å¤š URL æ•°ï¼‰:"))
        crawl_row.addWidget(self.crawl_max_urls_spin)

        source_layout.addLayout(crawl_row)

        # é™æ€é‡è¦ URLï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰ï¼Œç”¨äºæ‰‹åŠ¨è¡¥å……å…³é”®é¡µé¢
        self.static_urls_edit = QTextEdit()
        self.static_urls_edit.setPlaceholderText(
            "Static URLsï¼ˆoptionalï¼‰ï¼šone URL per line, for extremely important pages that are hard to discover.\n"
            "ä¾‹å¦‚ï¼š\nhttps://docs.example.com/interface-documentation\nhttps://www.example.com/special-landing-page"
        )
        self.static_urls_edit.setFixedHeight(80)
        source_layout.addWidget(QLabel("Static URLsï¼ˆæ‰‹å·¥è¡¥å…… URLï¼Œå¯é€‰ï¼‰:"))
        source_layout.addWidget(self.static_urls_edit)

        source_group.setLayout(source_layout)
        content_layout.addWidget(source_group)

        # è¿‡æ»¤è§„åˆ™
        filter_group = QGroupBox("Filters / è¿‡æ»¤è§„åˆ™")
        filter_layout = QVBoxLayout()

        self.auto_filter_lang_check = QCheckBox(
            "Auto-filter languagesï¼ˆä»…ä¿ç•™é»˜è®¤è¯­è¨€å¯¹åº”å†…å®¹ï¼‰"
        )
        self.auto_filter_lang_check.setChecked(True)
        filter_layout.addWidget(self.auto_filter_lang_check)

        # æ˜¯å¦å¯ç”¨å†…ç½®çš„é€šç”¨æ’é™¤è§„åˆ™ï¼ˆæœç´¢ã€åˆ†é¡µã€feedã€404 ç­‰ï¼‰
        self.use_default_excludes_check = QCheckBox(
            "Use built-in default excludesï¼ˆsearchã€tagã€feedã€404 ç­‰å¸¸è§å™ªå£°ï¼‰"
        )
        self.use_default_excludes_check.setChecked(True)
        filter_layout.addWidget(self.use_default_excludes_check)

        self.exclude_blog_check = QCheckBox("Exclude Blog Pagesï¼ˆæ’é™¤ /blog ä¸‹æ–‡ç« ï¼‰")
        self.exclude_blog_check.setChecked(False)  # é»˜è®¤ä¸æ’é™¤blog
        self.exclude_blog_check.setToolTip(
            "If checked, excludes /blog/ paths. Uncheck to include blog articles."
        )
        filter_layout.addWidget(self.exclude_blog_check)

        # ä¸€äº›å¸¸è§å¯é€‰æ’é™¤é¡¹ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥å‹¾é€‰ï¼Œæ— éœ€å†™æ­£åˆ™
        self.exclude_careers_check = QCheckBox("Exclude careers pagesï¼ˆæ’é™¤ /careersï¼‰")
        self.exclude_careers_check.setChecked(True)
        filter_layout.addWidget(self.exclude_careers_check)

        self.exclude_news_check = QCheckBox(
            "Exclude news/pressï¼ˆæ’é™¤ /news, /newsroomï¼‰"
        )
        self.exclude_news_check.setChecked(True)
        filter_layout.addWidget(self.exclude_news_check)

        self.exclude_admin_check = QCheckBox(
            "Exclude admin/loginï¼ˆæ’é™¤ /admin, /login ç­‰ï¼‰"
        )
        self.exclude_admin_check.setChecked(False)
        filter_layout.addWidget(self.exclude_admin_check)

        # Profile é€‰æ‹©ï¼ˆminimal / recommended / fullï¼‰ï¼Œç”¨äºç”Ÿæˆæ—¶ä¸€é”®æ§åˆ¶åˆ†ç»„æ¡£ä½
        profile_row = QHBoxLayout()
        profile_row.addWidget(QLabel("Profileï¼ˆè¾“å‡ºæ¡£ä½ï¼Œå¯é€‰ï¼‰:"))
        self.profile_combo = QComboBox()
        self.profile_combo.addItem("Autoï¼ˆauto-select by config / é»˜è®¤ï¼‰", "")
        self.profile_combo.addItem("minimal", "minimal")
        self.profile_combo.addItem("recommended", "recommended")
        self.profile_combo.addItem("full", "full")
        profile_row.addWidget(self.profile_combo)
        filter_layout.addLayout(profile_row)

        filter_group.setLayout(filter_layout)
        content_layout.addWidget(filter_group)

        # è¾“å‡ºé…ç½®
        output_group = QGroupBox("Output / è¾“å‡ºæ–‡ä»¶")
        output_layout = QVBoxLayout()

        # åŸºæœ¬è¾“å‡ºè·¯å¾„ï¼ˆllms.txt / llms-full.txt / llms.jsonï¼‰
        self.llms_txt_input = QLineEdit("llms.txt")
        self.llms_full_input = QLineEdit("llms-full.txt")
        self.llms_json_input = QLineEdit("llms.json")

        row_llms = QHBoxLayout()
        row_llms.addWidget(QLabel("llms.txt:"))
        row_llms.addWidget(self.llms_txt_input)
        output_layout.addLayout(row_llms)

        row_full = QHBoxLayout()
        row_full.addWidget(QLabel("llms-full.txt:"))
        row_full.addWidget(self.llms_full_input)
        output_layout.addLayout(row_full)

        row_json = QHBoxLayout()
        row_json.addWidget(QLabel("llms.json:"))
        row_json.addWidget(self.llms_json_input)
        output_layout.addLayout(row_json)

        # sitemap è¾“å‡º
        self.sitemap_xml_input = QLineEdit("sitemap.xml")
        self.sitemap_index_input = QLineEdit("sitemap_index.xml")

        row_sitemap = QHBoxLayout()
        row_sitemap.addWidget(QLabel("sitemap.xml:"))
        row_sitemap.addWidget(self.sitemap_xml_input)
        output_layout.addLayout(row_sitemap)

        row_index = QHBoxLayout()
        row_index.addWidget(QLabel("sitemap_index.xml:"))
        row_index.addWidget(self.sitemap_index_input)
        output_layout.addLayout(row_index)

        # ç”Ÿæˆæ—¶çš„æœ€å¤§é¡µé¢æ•°ï¼ˆé˜²æ­¢ä¸€æ¬¡æ€§è¾“å‡ºè¿‡å¤§ï¼‰
        max_pages_row = QHBoxLayout()
        max_pages_row.addWidget(QLabel("Max pages for generateï¼ˆç”Ÿæˆé¡µæ•°ä¸Šé™ï¼Œ0 è¡¨ç¤ºä¸é™ï¼‰:"))
        self.generate_max_pages_spin = QSpinBox()
        self.generate_max_pages_spin.setRange(0, 100000)
        self.generate_max_pages_spin.setValue(0)
        max_pages_row.addWidget(self.generate_max_pages_spin)
        output_layout.addLayout(max_pages_row)

        output_group.setLayout(output_layout)
        content_layout.addWidget(output_group)

        content_layout.addStretch(1)

        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAsNeeded)
        scroll.setVerticalScrollBarPolicy(Qt.ScrollBarAsNeeded)
        scroll.setWidget(content)
        layout.addWidget(scroll, 1)

        # åº•éƒ¨å›ºå®šæ“ä½œåŒºï¼šæ°¸è¿œå¯è§ï¼Œä¸ä¼šè¢«ä»»åŠ¡æ é®æŒ¡
        action_bar = QWidget()
        action_layout = QVBoxLayout(action_bar)
        action_layout.setContentsMargins(0, 0, 0, 0)
        action_layout.setSpacing(6)

        btn_layout = QHBoxLayout()
        btn_layout.setSpacing(8)

        self.load_config_btn = QPushButton("ğŸ“‚ Load Config")
        self.load_config_btn.setToolTip(
            "Load configuration from YAML file (e.g., llmstxt.config.yml)"
        )
        self.load_config_btn.clicked.connect(self.load_config_file)
        btn_layout.addWidget(self.load_config_btn)

        self.save_config_btn = QPushButton("ğŸ’¾ Save Config")
        self.save_config_btn.setToolTip("Save current settings to YAML file")
        self.save_config_btn.clicked.connect(self.save_config_file)
        btn_layout.addWidget(self.save_config_btn)

        btn_layout.addStretch(1)
        action_layout.addLayout(btn_layout)

        # ä¸»è¦åŠ¨ä½œæŒ‰é’®è¡Œ
        action_row = QHBoxLayout()
        action_row.setSpacing(8)

        self.collect_btn = QPushButton("Collect URLs / æ”¶é›† URL")
        self.collect_btn.clicked.connect(self.collect_urls)
        action_row.addWidget(self.collect_btn)

        self.generate_btn = QPushButton("Generate llms.txt / ç”Ÿæˆ llms.txt")
        self.generate_btn.clicked.connect(self.generate_output)
        self.generate_btn.setEnabled(False)
        action_row.addWidget(self.generate_btn)

        self.export_dead_links_btn = QPushButton("ğŸ› Export Dead Links / å¯¼å‡ºæ­»é“¾")
        self.export_dead_links_btn.clicked.connect(self.export_dead_links)
        self.export_dead_links_btn.setEnabled(False)
        self.export_dead_links_btn.setToolTip(
            "Export URLs that returned 404 or other errors during crawling.\n"
            "å¯¼å‡ºçˆ¬å–è¿‡ç¨‹ä¸­è¿”å› 404 æˆ–å…¶ä»–é”™è¯¯çš„ URLã€‚"
        )
        action_row.addWidget(self.export_dead_links_btn)

        action_layout.addLayout(action_row)

        # è¿›åº¦æ¡æ”¾åœ¨å›ºå®šåŒºåº•éƒ¨ï¼Œé¿å…æ»šåŠ¨æ—¶çœ‹ä¸åˆ°
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        action_layout.addWidget(self.progress_bar)

        layout.addWidget(action_bar, 0)
        return panel

    def create_preview_panel(self) -> QWidget:
        """åˆ›å»ºé¢„è§ˆé¢æ¿"""
        panel = QWidget()
        layout = QVBoxLayout(panel)
        layout.setContentsMargins(8, 8, 8, 8)
        layout.setSpacing(8)

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats_label = QLabel("Waiting to collect URLs / ç­‰å¾…æ”¶é›† URL ...")
        layout.addWidget(self.stats_label)

        # åˆ†ç»„æ ‘å½¢è§†å›¾ + URL åˆ—è¡¨ç”¨ splitter çºµå‘åˆ†å‰²ï¼Œä¾¿äºä¸Šä¸‹æ‹–æ‹½è°ƒæ•´é«˜åº¦
        splitter = QSplitter(Qt.Vertical)

        self.group_tree = QTreeWidget()
        self.group_tree.setHeaderLabels(
            ["Group / åˆ†ç»„", "URL Count / æ•°é‡", "Status / çŠ¶æ€"]
        )
        self.group_tree.itemChanged.connect(self.on_group_item_changed)
        splitter.addWidget(self.group_tree)

        # åˆ†ç»„å…¨é€‰ / å…¨ä¸é€‰ æŒ‰é’®
        group_btn_row = QHBoxLayout()
        self.select_all_groups_btn = QPushButton("Select All Groups / å…¨é€‰åˆ†ç»„")
        self.select_all_groups_btn.setToolTip(
            "Check all groups so that all filtered URLs are included."
        )
        self.select_all_groups_btn.clicked.connect(self.select_all_groups)
        group_btn_row.addWidget(self.select_all_groups_btn)

        self.deselect_all_groups_btn = QPushButton("Deselect All Groups / å…¨ä¸é€‰")
        self.deselect_all_groups_btn.setToolTip(
            "Uncheck all groups quickly, then you can pick only a few groups."
        )
        self.deselect_all_groups_btn.clicked.connect(self.deselect_all_groups)
        group_btn_row.addWidget(self.deselect_all_groups_btn)

        layout.addLayout(group_btn_row)

        url_panel = QWidget()
        url_panel_layout = QVBoxLayout(url_panel)
        url_panel_layout.setContentsMargins(0, 0, 0, 0)
        url_panel_layout.setSpacing(6)

        url_label = QLabel("URL List / URL åˆ—è¡¨:")
        url_panel_layout.addWidget(url_label)

        self.url_list = QTextEdit()
        self.url_list.setReadOnly(True)
        self.url_list.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        url_panel_layout.addWidget(self.url_list)

        splitter.addWidget(url_panel)
        splitter.setStretchFactor(0, 1)
        splitter.setStretchFactor(1, 1)
        layout.addWidget(splitter, 1)

        return panel

    def on_discover_subdomains(self):
        """å‘ç°å­åŸŸåå¹¶æ˜¾ç¤ºåœ¨åˆ—è¡¨ä¸­"""
        base_url = self.base_url_input.text().strip()
        if not base_url:
            QMessageBox.warning(
                self,
                "Missing URL / ç¼ºå°‘ URL",
                "Please enter a Base URL first before discovering subdomains.\n"
                "è¯·å…ˆè¾“å…¥åŸºç¡€ç½‘å€å†å‘ç°å­åŸŸåã€‚",
            )
            return

        import requests
        from .subdomain_discovery import discover_subdomains_comprehensive

        try:
            self.discover_subdomains_btn.setEnabled(False)
            self.discover_subdomains_btn.setText("ğŸ” Discovering... / å‘ç°ä¸­...")

            session = requests.Session()
            session.headers.setdefault(
                "User-Agent",
                "llms-sitemap-generator/0.1.0 (+https://github.com/thordata/llms-sitemap-generator)",
            )

            # å‘ç°å­åŸŸå
            discovered = discover_subdomains_comprehensive(base_url, session)
            self.discovered_subdomains = discovered

            # æ¸…ç©ºåˆ—è¡¨å¹¶æ·»åŠ å‘ç°çš„å­åŸŸå
            self.subdomain_list.clear()

            if not discovered:
                QMessageBox.information(
                    self,
                    "Discovery Result / å‘ç°ç»“æœ",
                    "No subdomains discovered.\næœªå‘ç°å­åŸŸåã€‚",
                )
                return

            # è§£æä¸»åŸŸå
            parsed = urlparse(base_url)
            main_domain = parsed.netloc.lower()

            for domain in sorted(discovered):
                item = QTreeWidgetItem(self.subdomain_list)
                item.setText(0, domain)
                item.setCheckState(0, Qt.Checked)

                # åˆ¤æ–­æ˜¯ä¸»åŸŸåè¿˜æ˜¯å­åŸŸå
                if domain == main_domain:
                    item.setText(1, "Main Domain / ä¸»åŸŸå")
                    item.setText(2, "Primary")
                else:
                    item.setText(1, "Subdomain / å­åŸŸå")
                    item.setText(2, "Discovered")

            # å¯ç”¨é€‰æ‹©æŒ‰é’®
            self.select_all_subdomains_btn.setEnabled(True)
            self.deselect_all_subdomains_btn.setEnabled(True)

            QMessageBox.information(
                self,
                "Discovery Complete / å‘ç°å®Œæˆ",
                f"Discovered {len(discovered)} subdomain(s):\n"
                f"å‘ç° {len(discovered)} ä¸ªå­åŸŸåï¼š\n\n"
                + "\n".join(sorted(discovered)),
            )

        except Exception as e:
            QMessageBox.critical(
                self,
                "Discovery Failed / å‘ç°å¤±è´¥",
                f"Failed to discover subdomains:\n{e}\n\nå­åŸŸåå‘ç°å¤±è´¥ï¼š\n{e}",
            )
        finally:
            self.discover_subdomains_btn.setEnabled(True)
            self.discover_subdomains_btn.setText("ğŸ” Discover Subdomains / å‘ç°å­åŸŸå")

    def select_all_subdomains(self):
        """é€‰æ‹©æ‰€æœ‰å­åŸŸå"""
        for i in range(self.subdomain_list.topLevelItemCount()):
            item = self.subdomain_list.topLevelItem(i)
            item.setCheckState(0, Qt.Checked)

    def deselect_all_subdomains(self):
        """å–æ¶ˆé€‰æ‹©æ‰€æœ‰å­åŸŸå"""
        for i in range(self.subdomain_list.topLevelItemCount()):
            item = self.subdomain_list.topLevelItem(i)
            item.setCheckState(0, Qt.Unchecked)

    def get_selected_subdomains(self) -> set:
        """è·å–ç”¨æˆ·é€‰æ‹©çš„å­åŸŸå"""
        selected = set()
        for i in range(self.subdomain_list.topLevelItemCount()):
            item = self.subdomain_list.topLevelItem(i)
            if item.checkState(0) == Qt.Checked:
                selected.add(item.text(0))
        return selected

    def build_config_from_ui(self) -> AppConfig:
        """ä» UI è¾“å…¥æ„å»ºé…ç½®å¯¹è±¡"""
        # å¦‚æœä¹‹å‰é€šè¿‡â€œåŠ è½½é…ç½®â€å¯¼å…¥äº†å®Œæ•´é…ç½®ï¼Œè¿™é‡Œåœ¨å…¶åŸºç¡€ä¸Šè¿›è¡Œä¿®æ”¹ï¼Œ
        # å°½é‡ä¿ç•™é«˜çº§ include / group_limits / profiles ç­‰è®¾ç½®ï¼Œé¿å… GUI è¦†ç›–æ‰æ‰‹å†™é…ç½®ã€‚
        base_config: Optional[AppConfig] = self.config

        base_url = self.base_url_input.text().strip()
        if not base_url:
            raise ValueError("Base URL ä¸èƒ½ä¸ºç©º")

        default_language = self.default_lang_input.text().strip() or "en"
        parsed = urlparse(base_url)
        main_domain = parsed.netloc.lower()

        # å¦‚æœä¹‹å‰åŠ è½½è¿‡é…ç½®ï¼Œä½†ç°åœ¨ç”¨æˆ·è¾“å…¥çš„ base_url å·²ç»åˆ‡æ¢åˆ°å®Œå…¨ä¸åŒçš„ç«™ç‚¹ï¼Œ
        # åˆ™è§†ä¸ºâ€œæ–°ç«™ç‚¹é…ç½®â€ï¼Œé¿å…ç»§ç»­æ²¿ç”¨æ—§ç«™ç‚¹ï¼ˆå¦‚ thordata.comï¼‰çš„ allowed_domains å’Œ sourcesï¼Œ
        # ä»¥å…å‡ºç°â€œæ˜æ˜è¾“å…¥äº†æ–°ç«™ç‚¹ï¼Œä½†è¿˜æ˜¯åœ¨çˆ¬æ—§ç«™ç‚¹â€çš„å›°æƒ‘ã€‚
        if base_config is not None:
            old_host = urlparse(base_config.site.base_url).netloc.lower()

            def _root_domain(host: str) -> str:
                parts = host.split(".")
                return ".".join(parts[-2:]) if len(parts) >= 2 else host

            if _root_domain(old_host) != _root_domain(main_domain):
                # ä¸åŒæ ¹åŸŸåï¼šé‡ç½®ä¸ºå…¨æ–°é…ç½®ï¼Œä»…ä¿ç•™è¿‡æ»¤ä¸è¾“å‡ºç­–ç•¥
                base_config = None

        allowed_domains = [main_domain]

        # å¦‚æœ base_config ä¸­å·²ç»æœ‰ allowed_domainsï¼Œåˆ™åˆå¹¶ï¼ˆé¿å…ä¸¢å¤±æ‰‹å†™çš„å…¶ä»–å­åŸŸï¼‰
        if base_config is not None and base_config.site.allowed_domains:
            for d in base_config.site.allowed_domains:
                d = d.lower()
                if d and d not in allowed_domains:
                    allowed_domains.append(d)

        # å¦‚æœ sitemap URL åŒ…å«ä¸åŒåŸŸåï¼Œä¹Ÿæ·»åŠ 
        sitemap_url = self.sitemap_url_input.text().strip()
        if sitemap_url:
            parsed_sitemap = urlparse(sitemap_url)
            sitemap_domain = parsed_sitemap.netloc.lower()
            if sitemap_domain and sitemap_domain not in allowed_domains:
                allowed_domains.append(sitemap_domain)

        # ç«™ç‚¹æè¿°ï¼šä¼˜å…ˆä½¿ç”¨ UI ä¸­è¾“å…¥ï¼Œå…¶æ¬¡æ²¿ç”¨å·²æœ‰é…ç½®
        site_description = self.site_desc_edit.toPlainText().strip()
        if not site_description and base_config is not None:
            site_description = base_config.site.description or ""

        # æ„å»ºç«™ç‚¹é…ç½®
        site = SiteConfig(
            base_url=base_url.rstrip("/"),
            default_language=default_language,
            allowed_domains=allowed_domains,
            description=site_description or None,
        )

        # -------- æ•°æ®æºé…ç½® --------
        sources: List[SourceConfig] = []

        if base_config is not None and base_config.sources:
            # ä»å·²æœ‰é…ç½®æ‹·è´ä¸€ä»½ï¼Œé¿å…ç›´æ¥ä¿®æ”¹åŸå¯¹è±¡
            for src in base_config.sources:
                copied = SourceConfig(
                    type=src.type,
                    url=src.url,
                    max_depth=src.max_depth,
                    max_urls=src.max_urls,
                    urls=list(src.urls),
                )
                sources.append(copied)

            # å¦‚æœ UI ä¸­å¡«å†™äº† sitemapï¼Œåˆ™è¦†ç›–/è¡¥å…… sitemap æº
            if sitemap_url:
                sitemap_source = next((s for s in sources if s.type == "sitemap"), None)
                if sitemap_source:
                    sitemap_source.url = sitemap_url
                else:
                    sources.append(SourceConfig(type="sitemap", url=sitemap_url))
        else:
            # æ— å·²æœ‰é…ç½®æ—¶ï¼Œç”¨ UI æ„å»ºåŸºç¡€ sources
            if sitemap_url:
                sources.append(SourceConfig(type="sitemap", url=sitemap_url))

        # æ ¹æ® UI çš„ crawl / static è®¾ç½®è¡¥å……æ•°æ®æº
        crawl_url = self.crawl_url_input.text().strip()
        if crawl_url:
            sources.append(
                SourceConfig(
                    type="crawl",
                    url=crawl_url,
                    max_depth=int(self.crawl_depth_spin.value()),
                    max_urls=int(self.crawl_max_urls_spin.value()),
                )
            )

        static_urls_text = self.static_urls_edit.toPlainText().strip()
        if static_urls_text:
            static_urls = [
                line.strip() for line in static_urls_text.splitlines() if line.strip()
            ]
            if static_urls:
                sources.append(SourceConfig(type="static", urls=static_urls))

        # å…³é”®ä¿®å¤ï¼šæ€»æ˜¯æ·»åŠ ä¸€ä¸ªä» base_url å¼€å§‹çš„ crawl æºï¼Œä½œä¸º sitemap çš„è¡¥å……
        # è¿™æ ·å¯ä»¥ç¡®ä¿å‘ç° sitemap ä¸­æ²¡æœ‰è¦†ç›–åˆ°çš„æ·±å±‚é¡µé¢
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ä» base_url å¼€å§‹çš„ crawl æº
        has_base_crawl = any(
            s.type == "crawl" and s.url.rstrip("/") == base_url.rstrip("/")
            for s in sources
        )

        if not has_base_crawl:
            logger.info(
                f"Adding base crawl source from {base_url} to supplement sitemap"
            )
            sources.append(
                SourceConfig(
                    type="crawl",
                    url=base_url.rstrip("/"),
                    max_depth=int(self.crawl_depth_spin.value()),
                    max_urls=int(self.crawl_max_urls_spin.value()),
                )
            )

        # Optional: Auto-add common content sections if not excluded
        # This is a convenience feature that can be disabled if not needed
        # Users can manually add crawl sources for specific sections if needed
        common_sections = ["/blog", "/docs", "/documentation"]
        for section in common_sections:
            section_url = f"{base_url.rstrip('/')}{section}"
            has_section_crawl = any(
                s.type == "crawl" and s.url.rstrip("/") == section_url for s in sources
            )
            # Only auto-add if:
            # 1. Not already in sources
            # 2. Not explicitly excluded (for blog, check exclude_blog_check)
            # 3. User hasn't disabled this feature
            should_add = False
            if section == "/blog" and not self.exclude_blog_check.isChecked():
                should_add = True
            elif section in ["/docs", "/documentation"]:
                # For docs, always try to add if not present (docs are usually important)
                should_add = True
            
            if should_add and not has_section_crawl:
                logger.info(f"Auto-adding crawl source for {section_url}")
                sources.append(
                    SourceConfig(
                        type="crawl",
                        url=section_url,
                        max_depth=int(self.crawl_depth_spin.value()),
                        max_urls=int(self.crawl_max_urls_spin.value()),
                    )
                )

        # å¦‚æœ sources åˆ—è¡¨ä»ç„¶ä¸ºç©ºï¼ˆç†è®ºä¸Šä¸ä¼šï¼Œä½†åšå®‰å…¨å…œåº•ï¼‰
        if not sources:
            # ä¼˜å…ˆå°è¯• sitemap
            default_sitemap_url = f"{base_url.rstrip('/')}/sitemap.xml"
            sources.append(SourceConfig(type="sitemap", url=default_sitemap_url))
            # åŒæ—¶æ·»åŠ ä¸€ä¸ªä» base_url å¼€å§‹çš„ crawl æº
            sources.append(
                SourceConfig(
                    type="crawl",
                    url=base_url.rstrip("/"),
                    max_depth=int(self.crawl_depth_spin.value()),
                    max_urls=int(self.crawl_max_urls_spin.value()),
                )
            )

        # -------- è¿‡æ»¤é…ç½® --------
        if base_config is not None:
            include_rules = list(base_config.filters.include)
            # å…ˆå¤åˆ¶ä¸€ä»½åŸå§‹ excludeï¼Œå†æ ¹æ®å‹¾é€‰æƒ…å†µå¢åˆ 
            base_excludes = list(base_config.filters.exclude)
            base_profiles = dict(base_config.filters.profiles)
            base_group_limits = dict(base_config.filters.group_limits)
            base_default_group_limit = base_config.filters.default_group_limit
        else:
            include_rules = []
            base_excludes = []
            base_profiles = {}
            base_group_limits = {}
            base_default_group_limit = None

        # ä» base_excludes ä¸­ç§»é™¤ç”± GUI æ§åˆ¶çš„å‡ ç±»è§„åˆ™ï¼ˆé¿å…é‡å¤ / ä¸å‹¾é€‰çŠ¶æ€å†²çªï¼‰
        controlled_prefixes = [
            "^/blog",
            "^/careers",
            "newsroom",
            "/news",
            "^/admin",
            "/login",
        ]
        exclude_rules: List[FilterRule] = []
        for r in base_excludes:
            if any(
                r.pattern.startswith(pfx) or pfx in r.pattern
                for pfx in controlled_prefixes
            ):
                continue
            exclude_rules.append(r)

        # åªæœ‰å½“ç”¨æˆ·æ˜ç¡®å‹¾é€‰"æ’é™¤Blog"æ—¶æ‰æ’é™¤/blog/è·¯å¾„ï¼ˆä¸æ’é™¤ blog å­åŸŸï¼‰
        if self.exclude_blog_check.isChecked():
            exclude_rules.append(FilterRule(pattern="^/blog/"))

        # å…¶ä»–å¸¸è§è·¯å¾„çš„æ’é™¤é¡¹
        if self.exclude_careers_check.isChecked():
            exclude_rules.append(FilterRule(pattern="^/careers"))

        if self.exclude_news_check.isChecked():
            exclude_rules.append(FilterRule(pattern="newsroom"))
            exclude_rules.append(FilterRule(pattern="/news"))

        if self.exclude_admin_check.isChecked():
            exclude_rules.append(FilterRule(pattern="^/admin"))
            exclude_rules.append(FilterRule(pattern="/login"))

        # max_urlsï¼šå¦‚æœå·²æœ‰é…ç½®ä¸­æœ‰æ›´å¤§çš„å€¼ï¼Œä¼˜å…ˆä¿ç•™æ›´å¤§è€…
        existing_max = base_config.filters.max_urls if base_config else 0
        max_urls = max(existing_max or 0, 5000)

        filters = FiltersConfig(
            include=include_rules,
            exclude=exclude_rules,
            max_urls=max_urls,
            auto_group=True,
            use_default_excludes=self.use_default_excludes_check.isChecked(),
            auto_filter_languages=self.auto_filter_lang_check.isChecked(),
            profiles=base_profiles,
            group_limits=base_group_limits,
            default_group_limit=base_default_group_limit,
        )

        # æ„å»ºè¾“å‡ºé…ç½®ï¼šåœ¨å·²æœ‰é…ç½®åŸºç¡€ä¸Šï¼Œå…è®¸é€šè¿‡ UI è¦†ç›–è¾“å‡ºè·¯å¾„
        if base_config is not None:
            base_output = base_config.output
        else:
            base_output = OutputConfig(
                llms_txt="llms.txt",
                llms_full_txt="llms-full.txt",
                llms_json="llms.json",
                sitemap_xml="sitemap.xml",
                sitemap_apply_filters=False,
            )

        def _norm_path(text: str | None) -> str | None:
            t = (text or "").strip()
            return t or None

        output = OutputConfig(
            llms_txt=_norm_path(self.llms_txt_input.text()) or base_output.llms_txt,
            llms_full_txt=_norm_path(self.llms_full_input.text())
            or base_output.llms_full_txt,
            llms_json=_norm_path(self.llms_json_input.text())
            or base_output.llms_json,
            sitemap_xml=_norm_path(self.sitemap_xml_input.text())
            or base_output.sitemap_xml,
            sitemap_index=_norm_path(self.sitemap_index_input.text())
            or base_output.sitemap_index,
            sitemap_apply_filters=base_output.sitemap_apply_filters,
            generate_full_text=base_output.generate_full_text,
        )

        app_config = AppConfig(
            site=site, sources=sources, filters=filters, output=output
        )

        # åœ¨ AppConfig ä¸ŠæŒ‚ä¸€ä¸ª GUI ä¸“ç”¨çš„åŠ¨æ€å±æ€§ï¼Œç”¨äºæ§åˆ¶æ˜¯å¦è‡ªåŠ¨æ ¹æ® sitemap å‘ç°å­åŸŸ
        # è¿™æ ·ä¸ä¼šç ´åç°æœ‰çš„é…ç½®æ–‡ä»¶ç»“æ„ï¼Œä½†çˆ¬è™«å±‚å¯ä»¥æ£€æµ‹åˆ°è¿™ä¸ªå¼€å…³ã€‚
        setattr(
            app_config,
            "enable_auto_subdomains",
            bool(self.auto_subdomains_check.isChecked()),
        )

        # æ·»åŠ ç”¨æˆ·é€‰æ‹©çš„å­åŸŸåï¼ˆå¦‚æœæœ‰ï¼‰
        selected_subdomains = self.get_selected_subdomains()
        if selected_subdomains:
            setattr(
                app_config,
                "selected_subdomains",
                selected_subdomains,
            )

        return app_config

    def collect_urls(self):
        """æ”¶é›† URL"""
        try:
            self.config = self.build_config_from_ui()
            # éªŒè¯é…ç½®ï¼šç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæ•°æ®æº
            if not self.config.sources:
                QMessageBox.warning(
                    self,
                    "Configuration Error / é…ç½®é”™è¯¯",
                    "No data sources configured. Please fill in at least one of:\n"
                    "æœªé…ç½®æ•°æ®æºã€‚è¯·è‡³å°‘å¡«å†™ä»¥ä¸‹ä¸€é¡¹ï¼š\n\n"
                    "- Sitemap URLï¼ˆæ¨èï¼‰\n"
                    "- Crawl Start URL\n"
                    "- Static URLs",
                )
                return
        except ValueError as e:
            QMessageBox.warning(
                self,
                "Configuration Error / é…ç½®é”™è¯¯",
                f"Cannot build configuration / æ— æ³•æ„å»ºé…ç½®:\n{e}",
            )
            return
        except Exception as e:
            QMessageBox.warning(
                self,
                "Configuration Error / é…ç½®é”™è¯¯",
                f"Unexpected error / æ„å¤–é”™è¯¯:\n{e}",
            )
            return

        self.collect_btn.setEnabled(False)
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)  # ä¸ç¡®å®šè¿›åº¦

        # å¯åŠ¨åå°çº¿ç¨‹
        self.collection_thread = URLCollectionThread(self.config)
        self.collection_thread.progress.connect(self.on_progress)
        self.collection_thread.finished.connect(self.on_urls_collected)
        self.collection_thread.error.connect(self.on_error)
        self.collection_thread.start()

    def on_progress(self, message: str):
        self.stats_label.setText(message)

    def on_urls_collected(self, urls: List[str], failed_urls: List[dict]):
        self.all_urls = urls
        self.failed_urls = failed_urls  # Store failed URLs for export
        self.collect_btn.setEnabled(True)
        self.progress_bar.setVisible(False)

        # å¯ç”¨/ç¦ç”¨å¯¼å‡ºæ­»é“¾æŒ‰é’®
        if hasattr(self, "export_dead_links_btn"):
            self.export_dead_links_btn.setEnabled(bool(failed_urls))

        if not urls:
            QMessageBox.warning(
                self,
                "No URLs Collected / æœªæ”¶é›†åˆ° URL",
                "No URLs were collected from the configured sources.\n"
                "æœªä»é…ç½®çš„æ•°æ®æºæ”¶é›†åˆ°ä»»ä½• URLã€‚\n\n"
                "Possible reasons / å¯èƒ½çš„åŸå› ï¼š\n"
                "1. Sitemap URL is incorrect or inaccessible\n"
                "   Sitemap URL ä¸æ­£ç¡®æˆ–æ— æ³•è®¿é—®\n"
                "2. Crawl Start URL is invalid or blocked\n"
                "   Crawl Start URL æ— æ•ˆæˆ–è¢«é˜»æ­¢\n"
                "3. Allowed domains are too restrictive\n"
                "   å…è®¸çš„åŸŸåé™åˆ¶è¿‡äºä¸¥æ ¼\n"
                "4. Network connectivity issues\n"
                "   ç½‘ç»œè¿æ¥é—®é¢˜\n\n"
                "Please check your configuration and try again.",
            )
            return

        # Show warning if there are failed URLs (404s, etc.)
        if failed_urls:
            dead_links_count = len(
                [u for u in failed_urls if u.get("status_code") == 404]
            )
            QMessageBox.information(
                self,
                "URL Collection Complete / URL æ”¶é›†å®Œæˆ",
                f"Successfully collected {len(urls)} URLs.\n"
                f"æˆåŠŸæ”¶é›† {len(urls)} ä¸ª URLã€‚\n\n"
                f"Found {len(failed_urls)} failed URLs ({dead_links_count} are 404 dead links).\n"
                f"å‘ç° {len(failed_urls)} ä¸ªå¤±è´¥çš„ URLï¼ˆå…¶ä¸­ {dead_links_count} ä¸ªæ˜¯ 404 æ­»é“¾ï¼‰ã€‚\n\n"
                f"You can export the failed URLs using 'Export Dead Links' button.\n"
                f"ä½ å¯ä»¥ä½¿ç”¨'å¯¼å‡ºæ­»é“¾'æŒ‰é’®å¯¼å‡ºå¤±è´¥çš„ URLã€‚",
            )

        # åº”ç”¨è¿‡æ»¤
        self.apply_filters()

    def on_error(self, error_msg: str):
        self.collect_btn.setEnabled(True)
        self.progress_bar.setVisible(False)

        # æä¾›é’ˆå¯¹å¸¸è§é”™è¯¯çš„å‹å¥½æç¤º
        detailed_msg = error_msg
        if (
            "not well-formed" in error_msg.lower()
            or "invalid token" in error_msg.lower()
        ):
            detailed_msg = (
                f"{error_msg}\n\n"
                "The sitemap XML appears to be malformed. / Sitemap XML æ ¼å¼ä¸æ­£ç¡®ã€‚\n\n"
                "Possible solutions / å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š\n"
                "1. Check if the sitemap URL is correct / æ£€æŸ¥ sitemap URL æ˜¯å¦æ­£ç¡®\n"
                "2. The sitemap might contain invalid characters / sitemap å¯èƒ½åŒ…å«æ— æ•ˆå­—ç¬¦\n"
                "3. Try disabling sitemap and use crawling instead / å°è¯•ç¦ç”¨ sitemapï¼Œæ”¹ç”¨çˆ¬å–\n\n"
                "Tip: You can leave the sitemap field empty and the tool will crawl from the homepage.\n"
                "æç¤ºï¼šå¯ä»¥å°† sitemap å­—æ®µç•™ç©ºï¼Œå·¥å…·å°†è‡ªåŠ¨ä»é¦–é¡µå¼€å§‹çˆ¬å–ã€‚"
            )
        elif "404" in error_msg or "not found" in error_msg.lower():
            detailed_msg = (
                f"{error_msg}\n\n"
                "The sitemap URL returned 404. / Sitemap URL è¿”å› 404ã€‚\n\n"
                "The tool will automatically crawl from the homepage instead.\n"
                "å·¥å…·å°†è‡ªåŠ¨ä»é¦–é¡µå¼€å§‹çˆ¬å–ã€‚"
            )

        QMessageBox.critical(
            self,
            "Collection Error / æ”¶é›†é”™è¯¯",
            f"Error collecting URLs / æ”¶é›† URL æ—¶å‡ºé”™:\n\n{detailed_msg}",
        )

    def apply_filters(self):
        """åº”ç”¨è¿‡æ»¤è§„åˆ™"""
        if not self.config:
            return

        try:
            self.filtered_pages = filter_and_group_urls(self.config, self.all_urls)
        except Exception as e:
            QMessageBox.warning(self, "è¿‡æ»¤é”™è¯¯", f"åº”ç”¨è¿‡æ»¤è§„åˆ™æ—¶å‡ºé”™: {e}")
            return

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        total = len(self.all_urls)
        filtered = len(self.filtered_pages)
        self.stats_label.setText(
            f"æ€» URL æ•°: {total} | è¿‡æ»¤å: {filtered} | æ’é™¤: {total - filtered}"
        )

        # æ›´æ–°åˆ†ç»„æ ‘
        self.update_group_tree()

        # æ›´æ–° URL åˆ—è¡¨
        self.update_url_list()

        self.generate_btn.setEnabled(True)

    def update_group_tree(self):
        """æ›´æ–°åˆ†ç»„æ ‘å½¢è§†å›¾"""
        self.group_tree.clear()
        self.group_tree.itemChanged.disconnect()  # ä¸´æ—¶æ–­å¼€ä¿¡å·ï¼Œé¿å…è§¦å‘è¿‡æ»¤

        from collections import defaultdict

        groups = defaultdict(list)
        for page in self.filtered_pages:
            groups[page.group].append(page)

        self.group_items = {}  # å­˜å‚¨åˆ†ç»„é¡¹ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾
        for group_name, pages in sorted(groups.items()):
            item = QTreeWidgetItem(self.group_tree)
            item.setText(0, group_name)
            item.setText(1, str(len(pages)))
            item.setCheckState(0, Qt.Checked)
            item.setData(0, Qt.UserRole, group_name)
            self.group_items[group_name] = item

        self.group_tree.itemChanged.connect(self.on_group_item_changed)  # é‡æ–°è¿æ¥ä¿¡å·

    def update_url_list(self):
        """æ›´æ–° URL åˆ—è¡¨ï¼ˆåªæ˜¾ç¤ºå·²å‹¾é€‰çš„åˆ†ç»„ï¼‰"""
        if not self.filtered_pages or not hasattr(self, "group_items"):
            self.url_list.clear()
            return

        # è·å–å·²å‹¾é€‰çš„åˆ†ç»„
        checked_groups = set()
        for group_name, item in self.group_items.items():
            if item.checkState(0) == Qt.Checked:
                checked_groups.add(group_name)

        # è¿‡æ»¤å‡ºå·²å‹¾é€‰åˆ†ç»„çš„ URL
        filtered_urls = [
            page.url for page in self.filtered_pages if page.group in checked_groups
        ]

        # åªæ˜¾ç¤ºå‰ 100 ä¸ª
        display_urls = filtered_urls[:100]
        self.url_list.setPlainText("\n".join(display_urls))
        if len(filtered_urls) > 100:
            self.url_list.append(f"\n... è¿˜æœ‰ {len(filtered_urls) - 100} ä¸ª URL")

    def on_group_item_changed(self, item: QTreeWidgetItem, column: int):
        """åˆ†ç»„é¡¹çŠ¶æ€æ”¹å˜"""
        if column != 0:
            return

        group_name = item.data(0, Qt.UserRole)
        is_checked = item.checkState(0) == Qt.Checked

        # æ›´æ–° URL åˆ—è¡¨æ˜¾ç¤ºï¼ˆåªæ˜¾ç¤ºå·²å‹¾é€‰çš„åˆ†ç»„ï¼‰
        self.update_url_list()

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.update_stats()

    def update_stats(self):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        if not hasattr(self, "group_items"):
            return

        checked_groups = set()
        for group_name, item in self.group_items.items():
            if item.checkState(0) == Qt.Checked:
                checked_groups.add(group_name)

        # ç»Ÿè®¡å·²å‹¾é€‰åˆ†ç»„çš„ URL æ•°é‡
        checked_count = sum(
            len([p for p in self.filtered_pages if p.group == g])
            for g in checked_groups
        )

        total = len(self.all_urls)
        filtered = len(self.filtered_pages)
        self.stats_label.setText(
            f"æ€» URL æ•°: {total} | è¿‡æ»¤å: {filtered} | å·²é€‰åˆ†ç»„: {checked_count} ä¸ª URL"
        )

    def _set_all_groups_checked(self, checked: bool):
        """å†…éƒ¨å·¥å…·ï¼šæ‰¹é‡å‹¾é€‰ / å–æ¶ˆå‹¾é€‰æ‰€æœ‰åˆ†ç»„"""
        if not hasattr(self, "group_items"):
            return
        # æš‚æ—¶æ–­å¼€ä¿¡å·ï¼Œé¿å…å¯¹æ¯ä¸ªåˆ†ç»„éƒ½å•ç‹¬è§¦å‘ä¸€æ¬¡è¿‡æ»¤
        try:
            self.group_tree.itemChanged.disconnect()
        except Exception:
            # å¦‚æœæœ¬æ¥å°±æ²¡è¿æ¥ï¼Œä¸å¿…æŠ¥é”™
            pass

        state = Qt.Checked if checked else Qt.Unchecked
        for item in self.group_items.values():
            item.setCheckState(0, state)

        # é‡æ–°è¿æ¥ä¿¡å·å¹¶åˆ·æ–°ç»Ÿè®¡/UI
        self.group_tree.itemChanged.connect(self.on_group_item_changed)
        self.update_url_list()
        self.update_stats()

    def select_all_groups(self):
        """ä¸€é”®å…¨é€‰æ‰€æœ‰åˆ†ç»„"""
        self._set_all_groups_checked(True)

    def deselect_all_groups(self):
        """ä¸€é”®å–æ¶ˆé€‰æ‹©æ‰€æœ‰åˆ†ç»„"""
        self._set_all_groups_checked(False)

    def export_dead_links(self):
        """å¯¼å‡ºæ­»é“¾ï¼ˆ404ç­‰å¤±è´¥çš„URLï¼‰"""
        if not hasattr(self, "failed_urls") or not self.failed_urls:
            QMessageBox.information(
                self,
                "No Dead Links / æ— æ­»é“¾",
                "No failed URLs to export.\næ²¡æœ‰å¤±è´¥çš„ URL éœ€è¦å¯¼å‡ºã€‚",
            )
            return

        # é€‰æ‹©ä¿å­˜æ–‡ä»¶
        file_path, _ = QFileDialog.getSaveFileName(
            self,
            "Export Dead Links / å¯¼å‡ºæ­»é“¾",
            str(Path.cwd() / "dead_links.txt"),
            "Text Files (*.txt);;CSV Files (*.csv);;All Files (*)",
        )
        if not file_path:
            return

        try:
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åå†³å®šæ ¼å¼
            is_csv = file_path.lower().endswith(".csv")

            with open(file_path, "w", encoding="utf-8") as f:
                if is_csv:
                    f.write("URL,Status Code,Error Message\n")
                    for item in self.failed_urls:
                        url = item.get("url", "")
                        status = item.get("status_code", "N/A")
                        error = item.get("error", "").replace(",", ";")
                        f.write(f"{url},{status},{error}\n")
                else:
                    f.write("# Dead Links / æ­»é“¾åˆ—è¡¨\n")
                    f.write(f"# Generated by LLMS Sitemap Generator\n")
                    f.write(f"# Total: {len(self.failed_urls)} failed URLs\n\n")

                    # æŒ‰çŠ¶æ€ç åˆ†ç»„
                    by_status = {}
                    for item in self.failed_urls:
                        status = item.get("status_code", "Unknown")
                        if status not in by_status:
                            by_status[status] = []
                        by_status[status].append(item)

                    for status in sorted(
                        by_status.keys(), key=lambda x: (x is None, x)
                    ):
                        items = by_status[status]
                        f.write(
                            f"\n## Status {status if status else 'Unknown'} ({len(items)} URLs)\n\n"
                        )
                        for item in items:
                            url = item.get("url", "")
                            error = item.get("error", "")
                            f.write(f"{url}\n")
                            if error:
                                f.write(f"  Error: {error}\n")

            QMessageBox.information(
                self,
                "Export Successful / å¯¼å‡ºæˆåŠŸ",
                f"Exported {len(self.failed_urls)} dead links to:\n"
                f"å¯¼å‡º {len(self.failed_urls)} ä¸ªæ­»é“¾åˆ°ï¼š\n\n"
                f"{file_path}",
            )
        except Exception as e:
            QMessageBox.critical(
                self,
                "Export Failed / å¯¼å‡ºå¤±è´¥",
                f"Failed to export dead links:\n{e}\n\nå¯¼å‡ºæ­»é“¾å¤±è´¥ï¼š\n{e}",
            )

    def generate_output(self):
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶"""
        if not self.config or not self.all_urls:
            QMessageBox.warning(
                self,
                "é…ç½®é”™è¯¯",
                "è¯·å…ˆç‚¹å‡»â€œæ”¶é›† URL / Collect URLsâ€å®Œæˆ URL æ”¶é›†ï¼Œå†ç”Ÿæˆ llms.txtã€‚",
            )
            return

        # è·å–å·²å‹¾é€‰çš„åˆ†ç»„
        checked_groups = None
        if hasattr(self, "group_items"):
            checked_groups = [
                group_name
                for group_name, item in self.group_items.items()
                if item.checkState(0) == Qt.Checked
            ]
            if not checked_groups:
                QMessageBox.warning(self, "æœªé€‰æ‹©åˆ†ç»„", "è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç»„")
                return

        try:
            output_path = Path("llms.txt")
            # ä»ä¸‹æ‹‰æ¡†è¯»å– profileï¼ˆminimal / recommended / fullï¼‰
            profile = None
            if hasattr(self, "profile_combo"):
                profile = self.profile_combo.currentData()
                if not profile:
                    profile = None

            # GUI é»˜è®¤ä»¥ã€Œå¿«é€Ÿæ¨¡å¼ã€ç”Ÿæˆï¼šä¸æŠ“å–é¡µé¢å†…å®¹ï¼Œåªå¤ç”¨å‰é¢å·²ç»æ”¶é›†å¥½çš„ URLï¼Œ
            # é¿å…å†æ¬¡è§¦å‘çˆ¬è™«ï¼Œå¤§å¹…ç¼©çŸ­åœ¨å¤§ç«™ç‚¹ä¸Šçš„ç”Ÿæˆæ—¶é—´ã€‚
            max_pages = None
            if hasattr(self, "generate_max_pages_spin"):
                val = int(self.generate_max_pages_spin.value())
                if val > 0:
                    max_pages = val

            generate_llms_from_urls(
                self.config,
                self.all_urls,
                output_path,
                fetch_content=False,
                profile=profile,
                only_groups=checked_groups if checked_groups else None,
                max_pages=max_pages,
            )
            QMessageBox.information(
                self,
                "ç”ŸæˆæˆåŠŸ",
                f"å·²ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶:\n"
                f"- llms.txt\n"
                f"- llms-full.txt\n"
                f"- llms.json\n"
                f"- sitemap.xml\n\n"
                f"ä¿å­˜ä½ç½®: {output_path.parent.absolute()}",
            )
        except Exception as e:
            QMessageBox.critical(self, "ç”Ÿæˆå¤±è´¥", f"ç”Ÿæˆæ—¶å‡ºé”™: {e}")

    def load_config_file(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "Load Configuration File",
            str(Path.cwd()),
            "YAML Files (*.yml *.yaml);;All Files (*)",
        )
        if not file_path:
            return

        try:
            config = load_config(Path(file_path))
            self.config = config

            # ------- æ›´æ–° UIï¼šç«™ç‚¹é…ç½® -------
            self.base_url_input.setText(config.site.base_url)
            self.default_lang_input.setText(config.site.default_language)
            self.site_desc_edit.setPlainText(config.site.description or "")

            # ------- æ•°æ®æº -------
            if config.sources:
                # sitemap æº
                sitemap_source = next(
                    (s for s in config.sources if s.type == "sitemap"), None
                )
                if sitemap_source:
                    self.sitemap_url_input.setText(sitemap_source.url)
                else:
                    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæ•°æ®æºçš„URL
                    self.sitemap_url_input.setText(config.sources[0].url)

                # crawl æºï¼ˆä¾‹å¦‚æ–‡æ¡£æˆ– blogï¼‰
                crawl_source = next(
                    (s for s in config.sources if s.type == "crawl"), None
                )
                if crawl_source:
                    self.crawl_url_input.setText(crawl_source.url or "")
                    if crawl_source.max_depth is not None:
                        self.crawl_depth_spin.setValue(int(crawl_source.max_depth))
                    if crawl_source.max_urls is not None:
                        self.crawl_max_urls_spin.setValue(int(crawl_source.max_urls))
                else:
                    self.crawl_url_input.clear()

                # static æºï¼šä»…å±•ç¤ºç¬¬ä¸€ä¸ª static çš„ URL åˆ—è¡¨
                static_source = next(
                    (s for s in config.sources if s.type == "static"), None
                )
                if static_source and static_source.urls:
                    self.static_urls_edit.setPlainText("\n".join(static_source.urls))
                else:
                    self.static_urls_edit.clear()
            else:
                self.sitemap_url_input.clear()
                self.crawl_url_input.clear()
                self.static_urls_edit.clear()

            # ------- è¿‡æ»¤è§„åˆ™ -------
            self.auto_filter_lang_check.setChecked(config.filters.auto_filter_languages)
            self.use_default_excludes_check.setChecked(
                config.filters.use_default_excludes
            )

            # æ£€æŸ¥æ˜¯å¦æœ‰ blog / careers / news / admin ç­‰æ’é™¤è§„åˆ™
            has_blog_exclude = any(
                "blog" in r.pattern.lower() and r.pattern.startswith("^/blog")
                for r in config.filters.exclude
            )
            self.exclude_blog_check.setChecked(has_blog_exclude)

            has_careers_exclude = any(
                r.pattern.startswith("^/careers") for r in config.filters.exclude
            )
            self.exclude_careers_check.setChecked(has_careers_exclude)

            has_news_exclude = any(
                ("newsroom" in r.pattern) or ("/news" in r.pattern)
                for r in config.filters.exclude
            )
            self.exclude_news_check.setChecked(has_news_exclude)

            has_admin_exclude = any(
                r.pattern.startswith("^/admin") or ("/login" in r.pattern)
                for r in config.filters.exclude
            )
            self.exclude_admin_check.setChecked(has_admin_exclude)

            # ------- Profile ä¸‹æ‹‰ï¼šæ ¹æ®é…ç½®ä¸­çš„ profiles åŠ¨æ€å¡«å…… -------
            self.profile_combo.clear()
            self.profile_combo.addItem("Autoï¼ˆæŒ‰é…ç½®æ–‡ä»¶æˆ–é»˜è®¤ç­–ç•¥ï¼‰", "")
            if config.filters.profiles:
                for name in sorted(config.filters.profiles.keys()):
                    self.profile_combo.addItem(name, name)
                # å¦‚æœæœ‰ recommendedï¼Œä¼˜å…ˆé€‰å®ƒ
                idx = self.profile_combo.findData("recommended")
                if idx != -1:
                    self.profile_combo.setCurrentIndex(idx)

            # ------- è¾“å‡ºé…ç½® -------
            # å¦‚æœé…ç½®ä¸­å·²æœ‰è¾“å‡ºè®¾ç½®ï¼Œåˆ™å¡«å……åˆ° UI
            if config.output:
                if hasattr(self, "llms_txt_input"):
                    self.llms_txt_input.setText(config.output.llms_txt or "llms.txt")
                if hasattr(self, "llms_full_input"):
                    self.llms_full_input.setText(
                        config.output.llms_full_txt or "llms-full.txt"
                    )
                if hasattr(self, "llms_json_input"):
                    self.llms_json_input.setText(
                        config.output.llms_json or "llms.json"
                    )
                if hasattr(self, "sitemap_xml_input"):
                    self.sitemap_xml_input.setText(
                        config.output.sitemap_xml or "sitemap.xml"
                    )
                if hasattr(self, "sitemap_index_input"):
                    self.sitemap_index_input.setText(
                        config.output.sitemap_index or "sitemap_index.xml"
                    )

            # æ˜¾ç¤ºæ›´è¯¦ç»†çš„ä¿¡æ¯
            sources_info = "\n".join(
                [f"  - {s.type}: {s.url}" for s in config.sources[:3]]
            )
            if len(config.sources) > 3:
                sources_info += f"\n  ... and {len(config.sources) - 3} more"

            QMessageBox.information(
                self,
                "Configuration Loaded",
                f"Successfully loaded: {Path(file_path).name}\n\n"
                f"Base URL: {config.site.base_url}\n"
                f"Allowed Domains: {len(config.site.allowed_domains)}\n"
                f"Data Sources: {len(config.sources)}\n"
                f"{sources_info}\n\n"
                f"Click 'Collect URLs' to start.",
            )
        except Exception as e:
            QMessageBox.critical(
                self,
                "Load Failed",
                f"Cannot load configuration file:\n{file_path}\n\nError: {e}\n\n"
                f"Please check the file format and try again.",
            )

    def save_config_file(self):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            config = self.build_config_from_ui()
        except Exception as e:
            QMessageBox.warning(
                self, "Configuration Error", f"Cannot build configuration: {e}"
            )
            return

        file_path, _ = QFileDialog.getSaveFileName(
            self,
            "Save Configuration File",
            str(Path.cwd() / "llmstxt.config.yml"),
            "YAML Files (*.yml *.yaml);;All Files (*)",
        )
        if not file_path:
            return

        if yaml is None:
            QMessageBox.critical(
                self,
                "Missing Dependency",
                "PyYAML is not installed. Cannot save configuration file.\n\n"
                "Please run: pip install PyYAML",
            )
            return

        try:
            from urllib.parse import urlparse

            # æ„å»ºé…ç½®å­—å…¸
            config_dict = {
                "site": {
                    "base_url": config.site.base_url,
                    "default_language": config.site.default_language,
                    "allowed_domains": config.site.allowed_domains,
                },
                "sources": [
                    {
                        "type": src.type,
                        "url": src.url,
                        "max_depth": src.max_depth if src.max_depth else None,
                        "max_urls": src.max_urls if src.max_urls else None,
                        "urls": src.urls if src.urls else None,
                    }
                    for src in config.sources
                    if any([src.type, src.url, src.urls])
                ],
                "filters": {
                    "exclude": [{"pattern": r.pattern} for r in config.filters.exclude],
                    "auto_filter_languages": config.filters.auto_filter_languages,
                    "max_urls": config.filters.max_urls,
                    "auto_group": config.filters.auto_group,
                    "use_default_excludes": config.filters.use_default_excludes,
                },
                "output": {
                    "llms_txt": config.output.llms_txt,
                    "llms_full_txt": config.output.llms_full_txt,
                    "llms_json": config.output.llms_json,
                    "sitemap_xml": config.output.sitemap_xml,
                    "sitemap_apply_filters": config.output.sitemap_apply_filters,
                },
            }

            # ç§»é™¤Noneå€¼
            def remove_none(d):
                if isinstance(d, dict):
                    return {k: remove_none(v) for k, v in d.items() if v is not None}
                elif isinstance(d, list):
                    return [remove_none(item) for item in d if item is not None]
                return d

            config_dict = remove_none(config_dict)

            with open(file_path, "w", encoding="utf-8") as f:
                yaml.dump(
                    config_dict,
                    f,
                    allow_unicode=True,
                    default_flow_style=False,
                    sort_keys=False,
                )

            QMessageBox.information(
                self,
                "Configuration Saved",
                f"Configuration saved successfully:\n{file_path}\n\n"
                f"You can now:\n"
                f"1. Edit the file manually if needed\n"
                f"2. Load it again using 'Load Config' button\n"
                f"3. Use it with CLI: llms-sitemap-generator generate -c {Path(file_path).name}",
            )
        except Exception as e:
            QMessageBox.critical(
                self,
                "Save Failed",
                f"Cannot save configuration file:\n{file_path}\n\nError: {e}",
            )


def main():
    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec_())


if __name__ == "__main__":
    main()
